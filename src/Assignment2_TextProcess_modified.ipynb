{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a2bebaa-692d-4ba7-8f23-0fbe780d6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import random\n",
    "import sklearn\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from gensim.models import Word2Vec\n",
    "import dateutil\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f693034-cb4e-46d6-bcee-bc3ee395379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c139a9c-2ce1-4ed6-9d72-120031bc0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridToIdx = {}\n",
    "with open('Mapping_recipe_id.csv', mode='r', encoding='utf-8') as fr:\n",
    "    reader = csv.DictReader(fr)\n",
    "    for row in reader:\n",
    "        key = row['recipe_id']\n",
    "        value = row['new_recipe_id']\n",
    "        if key not in ridToIdx:\n",
    "            ridToIdx[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e1fd25ca-d90f-4a8f-b088-b5468fcb791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uidToIdx = {}\n",
    "with open('Mapping_user_id.csv', mode='r', encoding='utf-8') as fr:\n",
    "    reader = csv.DictReader(fr)\n",
    "    for row in reader:\n",
    "        key = row['user_id']\n",
    "        value = row['new_user_id']\n",
    "        if key not in uidToIdx:\n",
    "            uidToIdx[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01e86d94-7824-464a-980b-fe20ada8125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemWords = {}\n",
    "with open('Mapping_stemword.csv', mode='r', encoding='utf-8') as fr:\n",
    "    reader = csv.DictReader(fr)\n",
    "    for row in reader:\n",
    "        key = row['word']\n",
    "        value = [row['word_id'], row['frequency']]\n",
    "        if key not in stemWords:\n",
    "            stemWords[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfb0e0aa-0239-48f1-b256-aba7d24c95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "49952604-1306-4cd4-bb49-938f8fa2cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Text-Preprocessing functions\n",
    "def preprocess_text(text):\n",
    "    text = ''.join([c.lower() if not c in punctuation else ' ' for c in text])\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words and not re.search(r'\\d', word)] # remove number tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b19954c-5aaa-451b-8047-3db4fe272a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RAW_recipes.csv\", mode='r', encoding='utf-8') as fr, \\\n",
    "    open('RAW_recipes_textProc.csv', mode='w', encoding='utf-8', newline='') as fw:\n",
    "    reader = csv.DictReader(fr)\n",
    "    writer = csv.DictWriter(fw, fieldnames=reader.fieldnames)\n",
    "    writer.writeheader()\n",
    "        \n",
    "    for row in reader:\n",
    "        row['description'] = preprocess_text(row['description'])\n",
    "        row['steps'] = preprocess_text(row['steps'])\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35daf40d-7abd-4fed-9add-d26cf72df8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}  # Will map words to indices\n",
    "index = 0\n",
    "uidToIdx = {}\n",
    "uIdx = 0\n",
    "\n",
    "with open(\"RAW_interactions.csv\", mode='r', encoding='utf-8') as fr:\n",
    "    reader = csv.DictReader(fr)\n",
    "    for row in reader:\n",
    "        if row['user_id'] not in uidToIdx:\n",
    "            uidToIdx[row['user_id']] = uIdx\n",
    "            uIdx += 1\n",
    "        r = ''.join([c for c in row['review'].lower() if not c in punctuation])\n",
    "        for w in r.split():\n",
    "            #w = stemmer.stem(w)                             # Stemming\n",
    "            if w not in stop_words and w not in vocabulary:  # If word is not a stopword and not in vocabulary\n",
    "                vocabulary[w] = index\n",
    "                index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a5597d6-40af-4bd7-84b1-e26981f2d87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329651"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a0887cd-1331-4111-bcfe-e7fe40559133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word count vector using the dictionary\n",
    "def create_count_vector(datum):\n",
    "    feat = [0 for _ in range(len(vocabulary))]\n",
    "    r = ''.join([c for c in datum['review'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        #w = stemmer.stem(w)                         # Stemming\n",
    "        if w not in stop_words and w in vocabulary:  # If it's not a stopword and it's in the vocabulary\n",
    "            feat[vocabulary[w]] += 1 \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "38757be6-7380-4f5a-8faa-8b1480395198",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RAW_interactions.csv\", mode='r', encoding='utf-8') as fr, \\\n",
    "    open('RAW_interactions_textProc.csv', mode='w', encoding='utf-8', newline='') as fw:\n",
    "    reader = csv.DictReader(fr)\n",
    "    fieldnames = reader.fieldnames\n",
    "    #fieldnames = reader.fieldnames + ['wordcount_vector']\n",
    "    writer = csv.DictWriter(fw, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        row['user_id'] = uidToIdx[row['user_id']]\n",
    "        row['recipe_id'] = ridToIdx[row['recipe_id']]\n",
    "        row['review'] = preprocess_text(row['review'])\n",
    "        #cnt_vec = create_count_vector(row)\n",
    "        #row['wordcount_vector'] = cnt_vec\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41e3a9bd-8345-4e91-aad5-4f1cfbe1c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mapping_user_id.csv', mode='w', encoding='utf-8', newline='') as fw:\n",
    "    fieldnames = ['user_id', 'new_user_id']\n",
    "    writer = csv.DictWriter(fw, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for key, value in uidToIdx.items():\n",
    "        row = {}\n",
    "        row['user_id'] = key\n",
    "        row['new_user_id'] = value\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "449b88a5-1d25-4658-8d4e-12d6c9a571f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemWords = {}\n",
    "wIdx = 0\n",
    "with open('RAW_interactions_textProc.csv', mode='r', encoding='utf-8') as fr:\n",
    "    reader = csv.DictReader(fr)\n",
    "    for row in reader:\n",
    "        rWords = row['review'].split()\n",
    "        for w in rWords:\n",
    "            if w not in stemWords:\n",
    "                stemWords[w] = [wIdx, 1]\n",
    "                wIdx += 1\n",
    "            else:\n",
    "                stemWords[w][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "76c73996-f194-495a-9783-7710b8ea7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mapping_stemword.csv', mode='w', encoding='utf-8', newline='') as fw:\n",
    "    fieldnames = ['word', 'word_id', 'frequency']\n",
    "    writer = csv.DictWriter(fw, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for key, value in stemWords.items():\n",
    "        row = {}\n",
    "        row['word'] = key\n",
    "        row['word_id'] = value[0]\n",
    "        row['frequency'] = value[1]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "226e85a7-d840-42dd-aa52-6028a9f2e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94828"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eb0ca3-7dff-4487-a111-0f57ce29e74a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
